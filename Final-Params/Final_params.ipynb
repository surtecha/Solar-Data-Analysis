{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data summary:\n",
      "              ssn         year       month     year_tsi   month_tsi  \\\n",
      "count  924.000000   924.000000  924.000000   924.000000  924.000000   \n",
      "mean    93.807468  1985.583333    6.500000  1985.583333    6.500000   \n",
      "std     71.508209    22.243618    3.453922    22.243618    3.453922   \n",
      "min      1.800000  1947.000000    1.000000  1947.000000    1.000000   \n",
      "25%     28.325000  1966.000000    3.750000  1966.000000    3.750000   \n",
      "50%     84.050000  1986.000000    6.500000  1986.000000    6.500000   \n",
      "75%    149.950000  2005.000000    9.250000  2005.000000    9.250000   \n",
      "max    285.000000  2024.000000   12.000000  2024.000000   12.000000   \n",
      "\n",
      "               tsi  \n",
      "count   924.000000  \n",
      "mean   1363.423637  \n",
      "std       0.354047  \n",
      "min    1362.889401  \n",
      "25%    1363.075220  \n",
      "50%    1363.427315  \n",
      "75%    1363.741120  \n",
      "max    1364.138153  \n",
      "Correlation between SSN and TSI: 0.9065\n",
      "PCA explained variance ratio: [9.99995630e-01 4.37041416e-06]\n",
      "Total number of combinations: 18\n",
      "\n",
      "Processing combination: seq6y_fh1m\n",
      "SSN - RMSE: 3.9773, PICP: 0.6047, MPIW: 12.1074\n",
      "TSI - RMSE: 0.0772, PICP: 0.2093, MPIW: 0.1058\n",
      "\n",
      "Processing combination: seq6y_fh3m\n",
      "SSN - RMSE: 5.5387, PICP: 0.4472, MPIW: 9.0149\n",
      "TSI - RMSE: 0.0960, PICP: 0.1138, MPIW: 0.0996\n",
      "\n",
      "Processing combination: seq6y_fh6m\n",
      "SSN - RMSE: 5.7272, PICP: 0.7018, MPIW: 14.0514\n",
      "TSI - RMSE: 0.1547, PICP: 0.0877, MPIW: 0.1346\n",
      "\n",
      "Processing combination: seq7y_fh1m\n",
      "SSN - RMSE: 3.5614, PICP: 0.5349, MPIW: 8.9964\n",
      "TSI - RMSE: 0.0647, PICP: 0.2791, MPIW: 0.0992\n",
      "\n",
      "Processing combination: seq7y_fh3m\n",
      "SSN - RMSE: 5.4046, PICP: 0.4390, MPIW: 8.9737\n",
      "TSI - RMSE: 0.0971, PICP: 0.0650, MPIW: 0.0937\n",
      "\n",
      "Processing combination: seq7y_fh6m\n",
      "SSN - RMSE: 6.5629, PICP: 0.8333, MPIW: 24.6598\n",
      "TSI - RMSE: 0.1443, PICP: 0.2105, MPIW: 0.1894\n",
      "\n",
      "Processing combination: seq8y_fh1m\n",
      "SSN - RMSE: 3.4655, PICP: 0.6512, MPIW: 7.6179\n",
      "TSI - RMSE: 0.0717, PICP: 0.0233, MPIW: 0.0746\n",
      "\n",
      "Processing combination: seq8y_fh3m\n",
      "SSN - RMSE: 5.0414, PICP: 0.5447, MPIW: 10.5583\n",
      "TSI - RMSE: 0.0983, PICP: 0.0325, MPIW: 0.0956\n",
      "\n",
      "Processing combination: seq8y_fh6m\n",
      "SSN - RMSE: 7.6419, PICP: 0.7018, MPIW: 24.5160\n",
      "TSI - RMSE: 0.1479, PICP: 0.2325, MPIW: 0.1758\n",
      "\n",
      "Processing combination: seq9y_fh1m\n",
      "SSN - RMSE: 3.9324, PICP: 0.4651, MPIW: 6.8961\n",
      "TSI - RMSE: 0.0741, PICP: 0.2326, MPIW: 0.0766\n",
      "\n",
      "Processing combination: seq9y_fh3m\n",
      "SSN - RMSE: 4.9435, PICP: 0.3902, MPIW: 7.7755\n",
      "TSI - RMSE: 0.1006, PICP: 0.0732, MPIW: 0.0954\n",
      "\n",
      "Processing combination: seq9y_fh6m\n",
      "SSN - RMSE: 6.4659, PICP: 0.8026, MPIW: 20.6056\n",
      "TSI - RMSE: 0.1741, PICP: 0.1316, MPIW: 0.1618\n",
      "\n",
      "Processing combination: seq10y_fh1m\n",
      "SSN - RMSE: 3.5372, PICP: 0.4884, MPIW: 7.4009\n",
      "TSI - RMSE: 0.0826, PICP: 0.0000, MPIW: 0.0714\n",
      "\n",
      "Processing combination: seq10y_fh3m\n",
      "SSN - RMSE: 4.9001, PICP: 0.5447, MPIW: 10.0824\n",
      "TSI - RMSE: 0.1126, PICP: 0.0081, MPIW: 0.1049\n",
      "\n",
      "Processing combination: seq10y_fh6m\n",
      "SSN - RMSE: 6.5449, PICP: 0.6623, MPIW: 14.7490\n",
      "TSI - RMSE: 0.1561, PICP: 0.1009, MPIW: 0.1240\n",
      "\n",
      "Processing combination: seq11y_fh1m\n",
      "SSN - RMSE: 3.5760, PICP: 0.5349, MPIW: 8.6235\n",
      "TSI - RMSE: 0.0748, PICP: 0.1163, MPIW: 0.0635\n",
      "\n",
      "Processing combination: seq11y_fh3m\n",
      "SSN - RMSE: 5.6638, PICP: 0.6748, MPIW: 15.6548\n",
      "TSI - RMSE: 0.0975, PICP: 0.2846, MPIW: 0.1397\n",
      "\n",
      "Processing combination: seq11y_fh6m\n",
      "SSN - RMSE: 6.9882, PICP: 0.7237, MPIW: 20.7949\n",
      "TSI - RMSE: 0.1634, PICP: 0.0921, MPIW: 0.1555\n",
      "\n",
      "Best combination: seq7y_fh6m\n",
      "Best SSN PICP: 0.8333\n",
      "Best TSI PICP: 0.2105\n",
      "Average PICP: 0.5219\n",
      "PCA-based forecasting process completed successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0=all, 1=info, 2=warning, 3=error\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "    df = df.set_index('date')\n",
    "    return df\n",
    "\n",
    "def create_forecast_sequences(data, seq_length, forecast_horizon):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - forecast_horizon + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length:i+seq_length+forecast_horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_lower, y_upper):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_lower = y_lower.flatten()\n",
    "    y_upper = y_upper.flatten()\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    within_interval = np.logical_and(y_true >= y_lower, y_true <= y_upper)\n",
    "    picp = np.mean(within_interval)\n",
    "    mpiw = np.mean(y_upper - y_lower)\n",
    "    \n",
    "    return rmse, picp, mpiw\n",
    "\n",
    "def create_train_model(X_train, y_train, forecast_horizon, n_features, model_dir, bootstrap_id):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], n_features)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon * n_features)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    checkpoint_path = os.path.join(model_dir, f\"pca_model_{bootstrap_id}.keras\")\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        save_weights_only=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def generate_bootstrap_forecasts(X_train, y_train, X_val, forecast_horizon, n_components, \n",
    "                                num_bootstraps=10, save_results=True, model_dir=\"\", results_dir=\"\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    forecasts = []\n",
    "    models = []\n",
    "\n",
    "    for i in range(num_bootstraps):\n",
    "        indices = np.random.choice(len(X_train), len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[indices]\n",
    "        y_bootstrap = y_train[indices]\n",
    "\n",
    "        model, _ = create_train_model(X_bootstrap, y_bootstrap, forecast_horizon, n_components, model_dir, i)\n",
    "        models.append(model)\n",
    "\n",
    "        forecast = model.predict(X_val, verbose=0)\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "    forecasts = np.array(forecasts)\n",
    "\n",
    "    mean_forecast = np.mean(forecasts, axis=0)\n",
    "    lower_bound = np.quantile(forecasts, 0.05, axis=0)\n",
    "    upper_bound = np.quantile(forecasts, 0.95, axis=0)\n",
    "\n",
    "    if save_results:\n",
    "        results = {\n",
    "            'mean_forecast': mean_forecast,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'forecasts': forecasts\n",
    "        }\n",
    "        \n",
    "        results_path = os.path.join(results_dir, 'pca_forecast_results.pkl')\n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "    return mean_forecast, lower_bound, upper_bound, models, forecasts\n",
    "\n",
    "def load_forecast_results(results_path):\n",
    "    if not os.path.exists(results_path):\n",
    "        raise FileNotFoundError(f\"Results file not found at {results_path}\")\n",
    "    \n",
    "    with open(results_path, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    return results['mean_forecast'], results['lower_bound'], results['upper_bound'], results['forecasts']\n",
    "\n",
    "def load_trained_models(num_bootstraps, model_dir):\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Model directory {model_dir} not found\")\n",
    "    \n",
    "    models = []\n",
    "    for i in range(num_bootstraps):\n",
    "        model_path = os.path.join(model_dir, f\"pca_model_{i}.keras\")\n",
    "        if os.path.exists(model_path):\n",
    "            model = load_model(model_path)\n",
    "            models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_future(model, last_sequence, future_steps, forecast_horizon, pca_scaler, pca, n_components, model_id):\n",
    "    future_predictions_pc = []\n",
    "    curr_sequence = last_sequence.copy()\n",
    "\n",
    "    steps_completed = 0\n",
    "    while steps_completed < future_steps:\n",
    "        curr_sequence_reshaped = curr_sequence.reshape(1, curr_sequence.shape[0], curr_sequence.shape[1])\n",
    "        next_preds = model.predict(curr_sequence_reshaped, verbose=0)[0]\n",
    "        \n",
    "        next_preds_reshaped = next_preds.reshape(forecast_horizon, n_components)\n",
    "        \n",
    "        steps_to_add = min(forecast_horizon, future_steps - steps_completed)\n",
    "        future_predictions_pc.extend(next_preds_reshaped[:steps_to_add])\n",
    "        \n",
    "        curr_sequence = np.roll(curr_sequence, -steps_to_add, axis=0)\n",
    "        \n",
    "        for i in range(steps_to_add):\n",
    "            curr_sequence[-steps_to_add+i] = next_preds_reshaped[i]\n",
    "        \n",
    "        steps_completed += steps_to_add\n",
    "\n",
    "    future_predictions_pc = np.array(future_predictions_pc)\n",
    "    \n",
    "    future_predictions_scaled = pca_scaler.inverse_transform(future_predictions_pc)\n",
    "    \n",
    "    future_predictions_original = pca.inverse_transform(future_predictions_scaled)\n",
    "    \n",
    "    future_predictions_ssn = future_predictions_original[:, 0].reshape(-1, 1)\n",
    "    future_predictions_tsi = future_predictions_original[:, 1].reshape(-1, 1)\n",
    "\n",
    "    return future_predictions_ssn, future_predictions_tsi, future_predictions_pc\n",
    "\n",
    "def generate_future_dates(last_date, num_months):\n",
    "    future_dates = pd.date_range(start=last_date, periods=num_months+1, freq='MS')[1:]\n",
    "    return future_dates\n",
    "\n",
    "def calculate_evaluation_metrics(actual_values, mean_forecast_inv, lower_bound_inv, upper_bound_inv):\n",
    "    rmse_values = []\n",
    "    picp_values = []\n",
    "    mpiw_values = []\n",
    "\n",
    "    for i in range(len(actual_values)):\n",
    "        rmse, picp, mpiw = calculate_metrics(\n",
    "            actual_values[i],\n",
    "            mean_forecast_inv[i],\n",
    "            lower_bound_inv[i],\n",
    "            upper_bound_inv[i]\n",
    "        )\n",
    "        rmse_values.append(rmse)\n",
    "        picp_values.append(picp)\n",
    "        mpiw_values.append(mpiw)\n",
    "\n",
    "    return np.mean(rmse_values), np.mean(picp_values), np.mean(mpiw_values)\n",
    "\n",
    "def plot_forecast(df, val_dates, mean_forecast_inv, lower_bound_inv, upper_bound_inv, \n",
    "                 future_dates, future_mean, future_lower, future_upper,\n",
    "                 cycle_24_start, cycle_25_start, forecast_horizon, target_var, output_path):\n",
    "    start_date = pd.to_datetime('1996-01-01')\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    historical_mask = df.index >= start_date\n",
    "    plt.plot(df.index[historical_mask], df[target_var][historical_mask], 'b-', label=f'Historical {target_var} Data')\n",
    "\n",
    "    for i in range(len(mean_forecast_inv)):\n",
    "        pred_dates = val_dates[i:i+forecast_horizon]\n",
    "        if len(pred_dates) == len(mean_forecast_inv[i]):\n",
    "            plt.plot(pred_dates, mean_forecast_inv[i], 'r-', alpha=0.5, label=f'Validation {target_var} Predictions' if i == 0 else \"\")\n",
    "            plt.fill_between(pred_dates, lower_bound_inv[i], upper_bound_inv[i], color='r', alpha=0.2, label='90% Confidence Interval' if i == 0 else \"\")\n",
    "\n",
    "    plt.plot(future_dates, future_mean, 'g-', label=f'Future {target_var} Predictions')\n",
    "    plt.fill_between(future_dates, future_lower.flatten(), future_upper.flatten(), color='g', alpha=0.2, label='Future 90% Confidence Interval')\n",
    "    plt.axvline(x=cycle_24_start, color='k', linestyle='--', label='Cycle 24 Start')\n",
    "    plt.axvline(x=cycle_25_start, color='k', linestyle='--', label='Cycle 25 Start')\n",
    "    plt.title(f'{target_var} Forecast (Seq: {seq_length//12} years, Horizon: {forecast_horizon} months)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{target_var}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_principal_components(pc_data, pc_dates, future_pc_data, future_dates, n_components, output_path):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    for i in range(n_components):\n",
    "        plt.subplot(n_components, 1, i+1)\n",
    "        plt.plot(pc_dates, pc_data[:, i], 'b-', label=f'Historical PC{i+1}')\n",
    "        plt.plot(future_dates, future_pc_data[:, i], 'g-', label=f'Forecast PC{i+1}')\n",
    "        plt.title(f'Principal Component {i+1}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_MODELS = True\n",
    "    \n",
    "    ssn_df = load_data('/Users/suryatejachalla/Projects/Solar-Data-Analysis/Data/processed/sunspot.csv')\n",
    "    tsi_df = load_data('/Users/suryatejachalla/Projects/Solar-Data-Analysis/Data/processed/tsi.csv')\n",
    "    \n",
    "    df = pd.merge(ssn_df, tsi_df, left_index=True, right_index=True, suffixes=('', '_tsi'))\n",
    "    df = df.rename(columns={'tsi_tsi': 'tsi'})\n",
    "    \n",
    "    print(\"Data summary:\")\n",
    "    print(df.describe())\n",
    "    print(f\"Correlation between SSN and TSI: {df['ssn'].corr(df['tsi']):.4f}\")\n",
    "    \n",
    "    features = df[['ssn', 'tsi']].values\n",
    "    \n",
    "    n_components = 2\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    pca_features = pca.fit_transform(features)\n",
    "    \n",
    "    print(\"PCA explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "    \n",
    "    pca_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    pca_scaled = pca_scaler.fit_transform(pca_features)\n",
    "    \n",
    "    with open('pca_model.pkl', 'wb') as f:\n",
    "        pickle.dump(pca, f)\n",
    "    with open('pca_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(pca_scaler, f)\n",
    "    \n",
    "    cycle_24_start = pd.to_datetime('2008-12-01')\n",
    "    cycle_25_start = pd.to_datetime('2019-12-01')\n",
    "    validation_start = pd.to_datetime('2021-01-01')\n",
    "    \n",
    "    train_data = pca_scaled[df.index < cycle_25_start]\n",
    "    val_data = pca_scaled[(df.index >= validation_start)]\n",
    "    val_dates = df.index[(df.index >= validation_start)]\n",
    "    \n",
    "    sequence_years = range(6, 12)\n",
    "    forecast_months = [1, 3, 6]\n",
    "    \n",
    "    num_bootstraps = 10\n",
    "    \n",
    "    last_date = df.index[-1]\n",
    "    future_steps = (2030 - last_date.year) * 12 + (12 - last_date.month)\n",
    "    future_dates = generate_future_dates(last_date, future_steps)\n",
    "    \n",
    "    print(f\"Total number of combinations: {len(sequence_years) * len(forecast_months)}\")\n",
    "    \n",
    "    base_output_dir = \"solar_forecast_combinations\"\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    \n",
    "    ssn_plots_dir = os.path.join(base_output_dir, \"ssn_plots\")\n",
    "    tsi_plots_dir = os.path.join(base_output_dir, \"tsi_plots\")\n",
    "    os.makedirs(ssn_plots_dir, exist_ok=True)\n",
    "    os.makedirs(tsi_plots_dir, exist_ok=True)\n",
    "    \n",
    "    best_combination = None\n",
    "    best_picp_ssn = 0\n",
    "    best_picp_tsi = 0\n",
    "    \n",
    "    for seq_years in sequence_years:\n",
    "        for fh in forecast_months:\n",
    "            seq_length = seq_years * 12\n",
    "            forecast_horizon = fh\n",
    "            \n",
    "            combo_name = f\"seq{seq_years}y_fh{forecast_horizon}m\"\n",
    "            print(f\"\\nProcessing combination: {combo_name}\")\n",
    "            \n",
    "            model_dir = os.path.join(base_output_dir, \"models\", combo_name)\n",
    "            results_dir = os.path.join(base_output_dir, \"results\", combo_name)\n",
    "            \n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            os.makedirs(results_dir, exist_ok=True)\n",
    "            \n",
    "            X_train, y_train = create_forecast_sequences(train_data, seq_length, forecast_horizon)\n",
    "            y_train_flattened = y_train.reshape(y_train.shape[0], -1)\n",
    "            \n",
    "            X_val = []\n",
    "            y_val_pc = []\n",
    "            \n",
    "            for i in range(len(val_dates) - forecast_horizon + 1):\n",
    "                start_idx = len(df.index[df.index < val_dates[i]]) - seq_length\n",
    "                end_idx = len(df.index[df.index < val_dates[i]])\n",
    "                \n",
    "                if start_idx >= 0 and end_idx < len(pca_scaled):\n",
    "                    X_val.append(pca_scaled[start_idx:end_idx])\n",
    "                    y_val_pc.append(pca_scaled[end_idx:end_idx+forecast_horizon])\n",
    "            \n",
    "            if not X_val:\n",
    "                print(f\"Skipping {combo_name}: Insufficient validation data\")\n",
    "                continue\n",
    "                \n",
    "            X_val = np.array(X_val)\n",
    "            y_val_pc = np.array(y_val_pc)\n",
    "            \n",
    "            if TRAIN_MODELS:\n",
    "                mean_forecast, lower_bound, upper_bound, models, forecasts = generate_bootstrap_forecasts(\n",
    "                    X_train, y_train_flattened, X_val, forecast_horizon, n_components, \n",
    "                    num_bootstraps=num_bootstraps, model_dir=model_dir, results_dir=results_dir\n",
    "                )\n",
    "            else:\n",
    "                results_path = os.path.join(results_dir, 'pca_forecast_results.pkl')\n",
    "                mean_forecast, lower_bound, upper_bound, forecasts = load_forecast_results(results_path)\n",
    "                models = load_trained_models(num_bootstraps, model_dir)\n",
    "            \n",
    "            mean_forecast_reshaped = mean_forecast.reshape(-1, forecast_horizon, n_components)\n",
    "            lower_bound_reshaped = lower_bound.reshape(-1, forecast_horizon, n_components)\n",
    "            upper_bound_reshaped = upper_bound.reshape(-1, forecast_horizon, n_components)\n",
    "            \n",
    "            mean_forecast_scaled = np.array([pca_scaler.inverse_transform(f) for f in mean_forecast_reshaped])\n",
    "            lower_bound_scaled = np.array([pca_scaler.inverse_transform(f) for f in lower_bound_reshaped])\n",
    "            upper_bound_scaled = np.array([pca_scaler.inverse_transform(f) for f in upper_bound_reshaped])\n",
    "            \n",
    "            mean_forecast_original = np.array([pca.inverse_transform(f) for f in mean_forecast_scaled])\n",
    "            lower_bound_original = np.array([pca.inverse_transform(f) for f in lower_bound_scaled])\n",
    "            upper_bound_original = np.array([pca.inverse_transform(f) for f in upper_bound_scaled])\n",
    "            \n",
    "            ssn_mean_forecast_inv = np.array([f[:, 0] for f in mean_forecast_original])\n",
    "            ssn_lower_bound_inv = np.array([f[:, 0] for f in lower_bound_original])\n",
    "            ssn_upper_bound_inv = np.array([f[:, 0] for f in upper_bound_original])\n",
    "            \n",
    "            tsi_mean_forecast_inv = np.array([f[:, 1] for f in mean_forecast_original])\n",
    "            tsi_lower_bound_inv = np.array([f[:, 1] for f in lower_bound_original])\n",
    "            tsi_upper_bound_inv = np.array([f[:, 1] for f in upper_bound_original])\n",
    "            \n",
    "            ssn_actual_values = []\n",
    "            tsi_actual_values = []\n",
    "            \n",
    "            for i in range(len(y_val_pc)):\n",
    "                pc_inv = pca_scaler.inverse_transform(y_val_pc[i])\n",
    "                original_inv = pca.inverse_transform(pc_inv)\n",
    "                \n",
    "                ssn_inv = original_inv[:, 0]\n",
    "                tsi_inv = original_inv[:, 1]\n",
    "                \n",
    "                ssn_actual_values.append(ssn_inv)\n",
    "                tsi_actual_values.append(tsi_inv)\n",
    "            \n",
    "            ssn_actual_values = np.array(ssn_actual_values)\n",
    "            tsi_actual_values = np.array(tsi_actual_values)\n",
    "            \n",
    "            ssn_avg_rmse, ssn_avg_picp, ssn_avg_mpiw = calculate_evaluation_metrics(\n",
    "                ssn_actual_values, ssn_mean_forecast_inv, ssn_lower_bound_inv, ssn_upper_bound_inv\n",
    "            )\n",
    "            \n",
    "            tsi_avg_rmse, tsi_avg_picp, tsi_avg_mpiw = calculate_evaluation_metrics(\n",
    "                tsi_actual_values, tsi_mean_forecast_inv, tsi_lower_bound_inv, tsi_upper_bound_inv\n",
    "            )\n",
    "            \n",
    "            print(f\"SSN - RMSE: {ssn_avg_rmse:.4f}, PICP: {ssn_avg_picp:.4f}, MPIW: {ssn_avg_mpiw:.4f}\")\n",
    "            print(f\"TSI - RMSE: {tsi_avg_rmse:.4f}, PICP: {tsi_avg_picp:.4f}, MPIW: {tsi_avg_mpiw:.4f}\")\n",
    "            \n",
    "            avg_picp = (ssn_avg_picp + tsi_avg_picp) / 2\n",
    "            if best_combination is None or avg_picp > (best_picp_ssn + best_picp_tsi) / 2:\n",
    "                best_combination = combo_name\n",
    "                best_picp_ssn = ssn_avg_picp\n",
    "                best_picp_tsi = tsi_avg_picp\n",
    "            \n",
    "            last_sequence = pca_scaled[-seq_length:].reshape(seq_length, n_components)\n",
    "            \n",
    "            future_ssn_forecasts = []\n",
    "            future_tsi_forecasts = []\n",
    "            future_pc_forecasts = []\n",
    "            \n",
    "            for i, model in enumerate(models):\n",
    "                future_ssn, future_tsi, future_pc = predict_future(\n",
    "                    model, last_sequence, future_steps, forecast_horizon, \n",
    "                    pca_scaler, pca, n_components, i\n",
    "                )\n",
    "                future_ssn_forecasts.append(future_ssn)\n",
    "                future_tsi_forecasts.append(future_tsi)\n",
    "                future_pc_forecasts.append(future_pc)\n",
    "            \n",
    "            future_ssn_forecasts = np.array(future_ssn_forecasts)\n",
    "            future_tsi_forecasts = np.array(future_tsi_forecasts)\n",
    "            future_pc_forecasts = np.array(future_pc_forecasts)\n",
    "            \n",
    "            future_ssn_mean = np.mean(future_ssn_forecasts, axis=0)\n",
    "            future_ssn_lower = np.quantile(future_ssn_forecasts, 0.05, axis=0)\n",
    "            future_ssn_upper = np.quantile(future_ssn_forecasts, 0.95, axis=0)\n",
    "            \n",
    "            future_tsi_mean = np.mean(future_tsi_forecasts, axis=0)\n",
    "            future_tsi_lower = np.quantile(future_tsi_forecasts, 0.05, axis=0)\n",
    "            future_tsi_upper = np.quantile(future_tsi_forecasts, 0.95, axis=0)\n",
    "            \n",
    "            future_pc_mean = np.mean(future_pc_forecasts, axis=0)\n",
    "            \n",
    "            future_results = {\n",
    "                'future_ssn_mean': future_ssn_mean,\n",
    "                'future_ssn_lower': future_ssn_lower,\n",
    "                'future_ssn_upper': future_ssn_upper,\n",
    "                'future_tsi_mean': future_tsi_mean,\n",
    "                'future_tsi_lower': future_tsi_lower,\n",
    "                'future_tsi_upper': future_tsi_upper,\n",
    "                'future_pc_mean': future_pc_mean,\n",
    "                'future_dates': future_dates,\n",
    "                'metrics': {\n",
    "                    'ssn_rmse': ssn_avg_rmse,\n",
    "                    'ssn_picp': ssn_avg_picp,\n",
    "                    'ssn_mpiw': ssn_avg_mpiw,\n",
    "                    'tsi_rmse': tsi_avg_rmse,\n",
    "                    'tsi_picp': tsi_avg_picp,\n",
    "                    'tsi_mpiw': tsi_avg_mpiw\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(os.path.join(results_dir, 'pca_future_predictions.pkl'), 'wb') as f:\n",
    "                pickle.dump(future_results, f)\n",
    "            \n",
    "            ssn_plot_path = os.path.join(ssn_plots_dir, f\"{combo_name}_ssn_forecast.png\")\n",
    "            tsi_plot_path = os.path.join(tsi_plots_dir, f\"{combo_name}_tsi_forecast.png\")\n",
    "            pc_plot_path = os.path.join(results_dir, f\"{combo_name}_principal_components.png\")\n",
    "            \n",
    "            plot_forecast(\n",
    "                df, val_dates, ssn_mean_forecast_inv, ssn_lower_bound_inv, ssn_upper_bound_inv,\n",
    "                future_dates, future_ssn_mean, future_ssn_lower, future_ssn_upper,\n",
    "                cycle_24_start, cycle_25_start, forecast_horizon, 'ssn', ssn_plot_path\n",
    "            )\n",
    "            \n",
    "            plot_forecast(\n",
    "                df, val_dates, tsi_mean_forecast_inv, tsi_lower_bound_inv, tsi_upper_bound_inv,\n",
    "                future_dates, future_tsi_mean, future_tsi_lower, future_tsi_upper,\n",
    "                cycle_24_start, cycle_25_start, forecast_horizon, 'tsi', tsi_plot_path\n",
    "            )\n",
    "            \n",
    "            plot_principal_components(\n",
    "                pca_scaled, df.index, future_pc_mean, future_dates, n_components, pc_plot_path\n",
    "            )\n",
    "    \n",
    "    print(f\"\\nBest combination: {best_combination}\")\n",
    "    print(f\"Best SSN PICP: {best_picp_ssn:.4f}\")\n",
    "    print(f\"Best TSI PICP: {best_picp_tsi:.4f}\")\n",
    "    print(f\"Average PICP: {(best_picp_ssn + best_picp_tsi) / 2:.4f}\")\n",
    "    print(\"PCA-based forecasting process completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
